"""
ê·œì¹™ ì „ìš© ì²˜ë¦¬ê¸° - AI í‰ê°€ ì—†ì´ ê¸°ë³¸ ê·œì¹™ë§Œìœ¼ë¡œ ì „ì²˜ë¦¬
"""
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging

from app.services.dsl_rules import dsl_manager
from app.core.database import db_manager

logger = logging.getLogger(__name__)


class RuleOnlyProcessor:
    """ê·œì¹™ ì „ìš© ì²˜ë¦¬ê¸° - AI í‰ê°€ ì—†ì´ ê¸°ë³¸ ê·œì¹™ë§Œ ì‚¬ìš©"""
    
    def __init__(self):
        self.processed_count = 0
        self.error_count = 0
        self.start_time = None
        
    async def process_all_precedents(self, batch_size: int = 100) -> Dict[str, Any]:
        """ëª¨ë“  íŒë¡€ë¥¼ ê¸°ë³¸ ê·œì¹™ë§Œìœ¼ë¡œ ì „ì²˜ë¦¬"""
        try:
            self.start_time = datetime.now()
            print(f"ğŸš€ ê¸°ë³¸ ê·œì¹™ ì „ìš© ì „ì²˜ë¦¬ ì‹œì‘ - ë°°ì¹˜ í¬ê¸°: {batch_size}")
            logger.info(f"ê·œì¹™ì „ìš©ì²˜ë¦¬ ì‹œì‘ - ë°°ì¹˜í¬ê¸°: {batch_size}")
            
            # MongoDB ì»¬ë ‰ì…˜ ì—°ê²°
            print("ğŸ” DEBUG: MongoDB ì»¬ë ‰ì…˜ ì—°ê²° ì‹œë„...")
            source_collection = db_manager.get_collection('processed_precedents')
            target_collection = db_manager.get_collection('cases')
            print(f"ğŸ” DEBUG: source_collection: {source_collection is not None}")
            print(f"ğŸ” DEBUG: target_collection: {target_collection is not None}")
            
            if source_collection is None:
                print("âŒ DEBUG: source_collectionì´ Noneì…ë‹ˆë‹¤")
                raise Exception("processed_precedents ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            if target_collection is None:
                print("âŒ DEBUG: target_collectionì´ Noneì…ë‹ˆë‹¤")
                raise Exception("cases ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            print("âœ… DEBUG: ì»¬ë ‰ì…˜ ê²€ì¦ ì™„ë£Œ")
            
            # ì „ì²´ ë¬¸ì„œ ìˆ˜ í™•ì¸
            print("ğŸ” DEBUG: count_documents í˜¸ì¶œ ì‹œì‘...")
            logger.info("count_documents í˜¸ì¶œ ì‹œì‘")
            try:
                # íƒ€ì„ì•„ì›ƒì„ ì„¤ì •í•˜ì—¬ ë¬´í•œ ëŒ€ê¸° ë°©ì§€
                import asyncio
                total_count = await asyncio.wait_for(
                    source_collection.count_documents({}), 
                    timeout=30.0  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                )
                print(f"ğŸ“Š ì „ì²´ íŒë¡€ ìˆ˜: {total_count:,}ê°œ")
            except asyncio.TimeoutError:
                print("âŒ DEBUG: count_documents íƒ€ì„ì•„ì›ƒ (30ì´ˆ ì´ˆê³¼)")
                logger.error("count_documents íƒ€ì„ì•„ì›ƒ")
                # ëŒ€ì²´ ë°©ë²•: estimated_document_count ì‚¬ìš©
                try:
                    print("ğŸ” DEBUG: estimated_document_count ì‹œë„...")
                    total_count = await source_collection.estimated_document_count()
                    print(f"ğŸ“Š ì¶”ì • íŒë¡€ ìˆ˜: {total_count:,}ê°œ (estimated)")
                except Exception as est_error:
                    print(f"âŒ DEBUG: estimated_document_countë„ ì‹¤íŒ¨: {est_error}")
                    # ìµœí›„ì˜ ìˆ˜ë‹¨: find().limit(1) í…ŒìŠ¤íŠ¸
                    print("ğŸ” DEBUG: ë‹¨ì¼ ë¬¸ì„œ ì¡°íšŒ í…ŒìŠ¤íŠ¸...")
                    test_doc = await source_collection.find_one({})
                    if test_doc:
                        print("âœ… DEBUG: ìµœì†Œ 1ê°œ ë¬¸ì„œëŠ” ì¡°íšŒ ê°€ëŠ¥")
                        total_count = 100  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‘ì€ ìˆ˜ë¡œ ì‹œì‘
                    else:
                        print("âŒ DEBUG: ë¬¸ì„œ ì¡°íšŒ ë¶ˆê°€ëŠ¥")
                        total_count = 0
            except Exception as count_error:
                print(f"âŒ DEBUG: count_documents ì‹¤íŒ¨: {count_error}")
                logger.error(f"count_documents ì‹¤íŒ¨: {count_error}")
                raise
            
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
            if total_count == 0:
                print("âš ï¸ processed_precedents ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {
                    "status": "completed",
                    "total_processed": 0,
                    "total_errors": 0,
                    "message": "processed_precedents ì»¬ë ‰ì…˜ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.",
                    "start_time": self.start_time.isoformat() if self.start_time else None,
                    "end_time": datetime.now().isoformat()
                }
            
            # í° ì»¬ë ‰ì…˜ì˜ ê²½ìš° ì²˜ë¦¬ëŸ‰ ì œí•œ
            if total_count > 1000:
                print(f"âš ï¸ í° ì»¬ë ‰ì…˜ ê°ì§€ ({total_count:,}ê°œ). í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì²˜ìŒ 1000ê°œë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                total_count = min(total_count, 1000)
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            processed = 0
            skip = 0
            
            while processed < total_count:
                print(f"ğŸ“‹ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: {processed:,}/{total_count:,} ({processed/total_count*100:.1f}%)")
                logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì§„í–‰: {processed}/{total_count}")
                
                # ë°°ì¹˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                try:
                    print(f"ğŸ” DEBUG: ë°°ì¹˜ ë°ì´í„° ì¡°íšŒ - skip: {skip}, limit: {batch_size}")
                    cursor = source_collection.find({}).skip(skip).limit(batch_size)
                    batch_docs = await cursor.to_list(length=batch_size)
                    print(f"ğŸ” DEBUG: ì¡°íšŒëœ ë¬¸ì„œ ìˆ˜: {len(batch_docs)}")
                except Exception as fetch_error:
                    print(f"âŒ DEBUG: ë°°ì¹˜ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {fetch_error}")
                    logger.error(f"ë°°ì¹˜ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {fetch_error}")
                    break
                
                if not batch_docs:
                    print("ğŸ” DEBUG: ë” ì´ìƒ ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŒ")
                    break
                
                # ë°°ì¹˜ ì²˜ë¦¬
                try:
                    print(f"ğŸ” DEBUG: ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ - {len(batch_docs)}ê°œ ë¬¸ì„œ")
                    batch_results = await self._process_batch(batch_docs)
                    print(f"ğŸ” DEBUG: ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ - {len(batch_results) if batch_results else 0}ê°œ ê²°ê³¼")
                except Exception as process_error:
                    print(f"âŒ DEBUG: ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {process_error}")
                    logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {process_error}")
                    self.error_count += len(batch_docs)
                    batch_results = []
                
                # ê²°ê³¼ ì €ì¥
                if batch_results:
                    try:
                        await target_collection.insert_many(batch_results)
                        print(f"âœ… ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {len(batch_results)}ê°œ")
                        self.processed_count += len(batch_results)
                    except Exception as save_error:
                        print(f"âŒ DEBUG: ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨: {save_error}")
                        logger.error(f"ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨: {save_error}")
                        self.error_count += len(batch_results)
                
                processed += len(batch_docs)
                skip += batch_size
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                if processed % 1000 == 0:
                    elapsed = (datetime.now() - self.start_time).total_seconds()
                    rate = processed / elapsed if elapsed > 0 else 0
                    remaining = (total_count - processed) / rate if rate > 0 else 0
                    print(f"â±ï¸ ì²˜ë¦¬ ì†ë„: {rate:.1f}ê±´/ì´ˆ, ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining/60:.1f}ë¶„")
            
            # ìµœì¢… ê²°ê³¼
            end_time = datetime.now()
            total_time = (end_time - self.start_time).total_seconds()
            
            return {
                "status": "completed",
                "total_processed": self.processed_count,
                "total_errors": self.error_count,
                "processing_time_seconds": total_time,
                "average_rate": self.processed_count / total_time if total_time > 0 else 0,
                "start_time": self.start_time.isoformat(),
                "end_time": end_time.isoformat()
            }
            
        except Exception as e:
            print(f"âŒ DEBUG: ì „ì²´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            print(f"âŒ DEBUG: ì˜ˆì™¸ íƒ€ì…: {type(e)}")
            print(f"âŒ DEBUG: ì˜ˆì™¸ ìœ„ì¹˜: {e.__traceback__.tb_lineno if e.__traceback__ else 'unknown'}")
            logger.error(f"ì „ì²´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
            return {
                "status": "failed",
                "error": str(e),
                "processed_count": self.processed_count,
                "error_count": self.error_count
            }
    
    async def _process_batch(self, batch_docs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ë¬¸ì„œë“¤ì„ ì²˜ë¦¬"""
        results = []
        
        for doc in batch_docs:
            try:
                result = await self._process_single_document(doc)
                if result:
                    results.append(result)
                    self.processed_count += 1
            except Exception as e:
                self.error_count += 1
                logger.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨ {doc.get('_id', 'unknown')}: {e}")
        
        return results
    
    async def _process_single_document(self, doc: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ë‹¨ì¼ ë¬¸ì„œ ì²˜ë¦¬"""
        try:
            # í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ
            original_content = self._extract_content(doc)
            if not original_content or len(original_content) < 50:
                return None
            
            # ê¸°ë³¸ ê·œì¹™ ì ìš©
            print(f"ğŸ” DEBUG: DSL ê·œì¹™ ì ìš© ì‹œì‘ - ì›ë³¸ ê¸¸ì´: {len(original_content)}ì")
            print(f"ğŸ” DEBUG: ë¡œë“œëœ ê·œì¹™ ìˆ˜: {len(dsl_manager.rules)}")
            print(f"ğŸ” DEBUG: í™œì„±í™”ëœ ê·œì¹™ ìˆ˜: {len([r for r in dsl_manager.rules.values() if r.enabled])}")
            
            processed_content, rule_results = dsl_manager.apply_rules(original_content)
            
            print(f"ğŸ” DEBUG: ê·œì¹™ ì ìš© ì™„ë£Œ - ì²˜ë¦¬ í›„ ê¸¸ì´: {len(processed_content)}ì")
            print(f"ğŸ” DEBUG: ì ìš©ëœ ê·œì¹™ ìˆ˜: {rule_results['stats']['applied_rule_count']}")
            print(f"ğŸ” DEBUG: ì ìš©ëœ ê·œì¹™ë“¤: {[rule['rule_id'] for rule in rule_results['applied_rules']]}")
            
            # ì²˜ë¦¬ í†µê³„
            original_length = len(original_content)
            processed_length = len(processed_content)
            reduction_rate = (original_length - processed_length) / original_length * 100 if original_length > 0 else 0
            
            # ê²°ê³¼ êµ¬ì„±
            result = {
                "original_id": str(doc.get("_id", "")),
                "precedent_id": doc.get("precedent_id", ""),
                "case_name": doc.get("case_name", ""),
                "case_number": doc.get("case_number", ""),
                "court_name": doc.get("court_name", ""),
                "court_type": doc.get("court_type", ""),
                "decision_date": doc.get("decision_date", ""),
                "original_content": original_content,
                "processed_content": processed_content,
                "processing_mode": "rule_only",
                "rules_version": dsl_manager.version,
                "original_length": original_length,
                "processed_length": processed_length,
                "reduction_rate": round(reduction_rate, 2),
                "applied_rules": [rule["rule_id"] for rule in rule_results["applied_rules"]],
                "applied_rule_count": rule_results["stats"]["applied_rule_count"],
                "rule_types_used": rule_results["stats"]["rule_types"],
                "processed_at": datetime.now().isoformat(),
                "status": "completed"
            }
            
            return result
            
        except Exception as e:
            logger.error(f"ë‹¨ì¼ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def _extract_content(self, doc: Dict[str, Any]) -> Optional[str]:
        """ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ"""
        # ë‹¤ì–‘í•œ í•„ë“œëª… ì‹œë„
        content_fields = ['content', 'text', 'body', 'document_text', 'full_text']
        
        for field in content_fields:
            content = doc.get(field)
            if content and isinstance(content, str) and len(content.strip()) > 0:
                return content.strip()
        
        return None
    
    async def test_processing(self, limit: int = 10) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ìš© ì†ŒëŸ‰ ì²˜ë¦¬"""
        try:
            start_time = datetime.now()
            print(f"ğŸ§ª ê·œì¹™ ì „ìš© í…ŒìŠ¤íŠ¸ ì²˜ë¦¬ ì‹œì‘ - {limit}ê°œ ë¬¸ì„œ")
            
            # MongoDB ì»¬ë ‰ì…˜ ì—°ê²°
            source_collection = db_manager.get_collection('processed_precedents')
            target_collection = db_manager.get_collection('cases')
            
            if source_collection is None:
                raise Exception("processed_precedents ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            if target_collection is None:
                raise Exception("cases ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° (ëœë¤ ìƒ˜í”Œ)
            pipeline = [
                {"$sample": {"size": limit}},
                {"$project": {
                    "_id": 1,
                    "precedent_id": 1,
                    "case_name": 1,
                    "case_number": 1,
                    "court_name": 1,
                    "court_type": 1,
                    "decision_date": 1,
                    "content": 1,
                    "text": 1,
                    "body": 1,
                    "document_text": 1,
                    "full_text": 1
                }}
            ]
            
            test_docs = await source_collection.aggregate(pipeline).to_list(limit)
            
            if not test_docs:
                return {
                    "processed_count": 0,
                    "avg_reduction_rate": 0.0,
                    "total_rules_applied": 0,
                    "rules_version": dsl_manager.version,
                    "processing_time_ms": 0,
                    "sample_results": [],
                    "error": "í…ŒìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                }
            
            # í…ŒìŠ¤íŠ¸ ë¬¸ì„œë“¤ ì²˜ë¦¬
            results = []
            saved_results = []  # cases ì»¬ë ‰ì…˜ì— ì €ì¥í•  ê²°ê³¼ë“¤
            total_reduction = 0.0
            total_rules_applied = 0
            
            for doc in test_docs:
                try:
                    result = await self._process_single_document(doc)
                    if result:
                        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ (API ì‘ë‹µìš©)
                        results.append({
                            "case_name": result["case_name"],
                            "original_length": result["original_length"],
                            "processed_length": result["processed_length"],
                            "reduction_rate": result["reduction_rate"],
                            "applied_rule_count": result["applied_rule_count"],
                            "applied_rules": result["applied_rules"][:5]  # ì²˜ìŒ 5ê°œë§Œ
                        })
                        
                        # cases ì»¬ë ‰ì…˜ ì €ì¥ìš© (ì „ì²´ ë°ì´í„°)
                        test_result = result.copy()
                        test_result["processing_mode"] = "rule_only_test"  # í…ŒìŠ¤íŠ¸ì„ì„ í‘œì‹œ
                        saved_results.append(test_result)
                        
                        total_reduction += result["reduction_rate"]
                        total_rules_applied += result["applied_rule_count"]
                except Exception as e:
                    logger.error(f"í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            # í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ cases ì»¬ë ‰ì…˜ì— ì €ì¥
            if saved_results:
                try:
                    # ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì™€ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ upsert ì‚¬ìš©
                    for result in saved_results:
                        await target_collection.update_one(
                            {
                                "original_id": result["original_id"],
                                "processing_mode": "rule_only_test"
                            },
                            {"$set": result},
                            upsert=True
                        )
                    print(f"âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {len(saved_results)}ê°œ â†’ cases ì»¬ë ‰ì…˜")
                except Exception as save_error:
                    print(f"âŒ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {save_error}")
                    logger.error(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {save_error}")
            
            # í†µê³„ ê³„ì‚°
            processed_count = len(results)
            avg_reduction_rate = total_reduction / processed_count if processed_count > 0 else 0.0
            processing_time_ms = int((datetime.now() - start_time).total_seconds() * 1000)
            
            print(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {processed_count}ê°œ ì²˜ë¦¬, í‰ê·  ì••ì¶•ë¥ : {avg_reduction_rate:.1f}%")
            
            return {
                "processed_count": processed_count,
                "avg_reduction_rate": round(avg_reduction_rate, 1),
                "total_rules_applied": total_rules_applied,
                "rules_version": dsl_manager.version,
                "processing_time_ms": processing_time_ms,
                "sample_results": results
            }
            
        except Exception as e:
            logger.error(f"í…ŒìŠ¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "processed_count": 0,
                "avg_reduction_rate": 0.0,
                "total_rules_applied": 0,
                "rules_version": "error",
                "processing_time_ms": 0,
                "sample_results": [],
                "error": str(e)
            }
    
    def get_progress_stats(self) -> Dict[str, Any]:
        """ì§„í–‰ ìƒí™© í†µê³„"""
        if self.start_time:
            elapsed = (datetime.now() - self.start_time).total_seconds()
            rate = self.processed_count / elapsed if elapsed > 0 else 0
        else:
            elapsed = 0
            rate = 0
        
        return {
            "processed_count": self.processed_count,
            "error_count": self.error_count,
            "elapsed_seconds": elapsed,
            "processing_rate": round(rate, 2),
            "status": "running" if self.start_time else "idle"
        }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
rule_only_processor = RuleOnlyProcessor()
